{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_code_simCLR_first_draft.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPz5pz8vjtvO"
      },
      "outputs": [],
      "source": [
        "#getting the latent features the unet model extracted from images for calculating contrastive loss\n",
        "def double_conv_layers(in_channels, out_channels, kernel_size, activation, padding=0, batch_norm=True):\n",
        "\n",
        "  if batch_norm:\n",
        "    double_conv = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n",
        "                                nn.BatchNorm2d(out_channels),\n",
        "                                activation(inplace=True),\n",
        "                                nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding),\n",
        "                                nn.BatchNorm2d(out_channels),\n",
        "                                activation(inplace=True))\n",
        "  else:\n",
        "    double_conv = nn.Sequential(\n",
        "                                nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding),\n",
        "                                activation(inplace=True),\n",
        "                                nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding),\n",
        "                                activation(inplace=True))\n",
        "  \n",
        "  return double_conv\n",
        "\n",
        "class SimCLR(nn.Module): \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.down_conv1 = double_conv_layers(3, 64, 3, nn.ReLU, padding=1)\n",
        "        self.down_conv2 = double_conv_layers(64, 128, 3, nn.ReLU, padding=1)\n",
        "        self.down_conv3 = double_conv_layers(128, 256, 3, nn.ReLU, padding=1)\n",
        "        self.down_conv4 = double_conv_layers(256, 512, 3, nn.ReLU, padding=1)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 256)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, projection == True):\n",
        "        x = torch.cat(x, dim=0)\n",
        "        x = self.maxpool(self.down_conv1(x))\n",
        "        x = self.maxpool(self.down_conv2(x))\n",
        "        x = self.maxpool(self.down_conv3(x))\n",
        "        x = self.down_conv4(x)\n",
        "        proj = self.projection(x)\n",
        "        if projection==True:\n",
        "          return proj\n",
        "        else:\n",
        "          return x\n",
        "\n",
        "class decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Conv Transpose layers\n",
        "        self.up_transpose1 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
        "        self.up_transpose2 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
        "        self.up_transpose3 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
        "    \n",
        "        # Up Conv Layers\n",
        "        self.up_conv1 = double_conv_layers(512, 256, 3, nn.ReLU, padding=1)\n",
        "        self.up_conv2 = double_conv_layers(256, 128, 3, nn.ReLU, padding=1)\n",
        "        self.up_conv3 = double_conv_layers(128, 64, 3, nn.ReLU, padding=1)\n",
        "\n",
        "        # final output conv\n",
        "        self.output_conv = nn.Conv2d(64, 3, 1)\n",
        "    def forward(self, x):\n",
        "        # Up Conv Decoder Part\n",
        "        x = self.up_transpose1(x4)\n",
        "        x = self.up_conv1(torch.cat([x, x3], 1)) # skip connection from down_conv3\n",
        "        x = self.up_transpose2(x)\n",
        "        x = self.up_conv2(torch.cat([x, x2], 1)) # skip connection from down_conv2\n",
        "        x = self.up_transpose3(x)\n",
        "        x = self.up_conv3(torch.cat([x, x1], 1)) # skip connection from down_conv1\n",
        "        # final output conv layer\n",
        "        x = self.output_conv(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "tglUlv0-mJKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infoNCE_loss(args, features):\n",
        "\n",
        "    labels = torch.cat([torch.arange(args.batch_size) for i in range(args.n_views)], dim=0)\n",
        "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float() \n",
        "    #labels = labels.to(self.args.device)\n",
        "\n",
        "    features = F.normalize(features, dim=1)\n",
        "\n",
        "    similarity_matrix = torch.matmul(features, features.T) \n",
        "    \n",
        "    mask = torch.eye(labels.shape[0], dtype=torch.bool) #.to(args.device)\n",
        "    # ~mask is the negative of the mask\n",
        "\n",
        "    labels = labels[~mask].view(labels.shape[0], -1) \n",
        "    similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1) \n",
        "\n",
        "    # select and combine multiple positives\n",
        "    positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1) \n",
        "\n",
        "    # select only the negatives\n",
        "    negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1) \n",
        "\n",
        "    logits = torch.cat([positives, negatives], dim=1) \n",
        "    labels = torch.zeros(logits.shape[0], dtype=torch.long) #.to(args.device)\n",
        "\n",
        "    logits = logits / args.temp\n",
        "\n",
        "    return logits, labels"
      ],
      "metadata": {
        "id": "gmXwOqEWmpLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the data should be in the form of pairs (each with a different mask) of an image like \n",
        "#[[image_mask1, image_mask2],[image1_mask1, image2_mask2]....]\n",
        "#function that takes one image and returns a masked pair ?\n",
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "\n",
        "def get_batch(x, batch_size):\n",
        "    N = np.shape(x)[0]\n",
        "    for i in range(0, N, batch_size):\n",
        "        batch = x[i : i + batch_size, :, :, :]\n",
        "        yield batch\n",
        "\n",
        "def get_torch_vars(xs, gpu=False):\n",
        "\n",
        "    xs = torch.from_numpy(xs).float()\n",
        "    if gpu:\n",
        "        xs = xs.cuda()\n",
        "\n",
        "    return Variable(xs)\n",
        "\n",
        "def train_simCLR(train, args, gen=None):\n",
        "\n",
        "    npr.seed(args.seed)\n",
        "\n",
        "    save_dir = \"outputs/\" + args.experiment_name\n",
        "\n",
        "    if gen is None:\n",
        "        Net = globals()[args.model]\n",
        "        #gen = Net(args.kernel, args.num_filters)\n",
        "        gen = Net()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(gen.parameters(), lr=args.learn_rate)\n",
        "\n",
        "    # Create the outputs folder if not created already\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    print(\"Beginning training ...\")\n",
        "    if args.gpu:\n",
        "        gen.cuda()\n",
        "    start = time.time()\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "       \n",
        "        gen.train()  \n",
        "        losses = []\n",
        "        for i, imgs in enumerate(get_batch(train, args.batch_size)):\n",
        "            imgs = get_torch_vars(imgs, args.gpu)\n",
        "            proj = gen([view for view in imgs])\n",
        "            logits, labels = infoNCE_loss(args, proj)\n",
        "            loss = criterion(logits, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        print(epoch, loss.cpu().detach())\n",
        "\n",
        "    return gen"
      ],
      "metadata": {
        "id": "QziDABTRsBR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = AttrDict()\n",
        "args_dict = {\n",
        "    \"gpu\": True,\n",
        "    \"valid\": False,\n",
        "    \"checkpoint\": \"\",\n",
        "    \"colours\": \"./data/colours/colour_kmeans24_cat7.npy\",\n",
        "    \"model\": \"SimCLR\",\n",
        "    'learn_rate':0.001, \n",
        "    \"batch_size\": 64,\n",
        "    \"epochs\": 50,\n",
        "    \"seed\": 0,\n",
        "    \"plot\": False,\n",
        "    \"experiment_name\": \"contrastive learning\",\n",
        "    \"visualize\": False,\n",
        "    \"downsize_input\": False,\n",
        "}\n",
        "args.update(args_dict)\n",
        "simCLR = train_simCLR(data, args)"
      ],
      "metadata": {
        "id": "mvq86vwD96dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the data here should be in the form of pairs with masked images and the original image?\n",
        "def train(train, args, simCLR, gen=None):\n",
        "\n",
        "    npr.seed(args.seed)\n",
        "\n",
        "    save_dir = \"outputs/\" + args.experiment_name\n",
        "\n",
        "    if gen is None:\n",
        "        Net = globals()[args.model]\n",
        "        gen = Net()\n",
        "        simCLR=simCLR()\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(gen.parameters(), lr=args.learn_rate)\n",
        "\n",
        "    # Create the outputs folder if not created already\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    print(\"Beginning training ...\")\n",
        "    if args.gpu:\n",
        "        gen.cuda()\n",
        "    start = time.time()\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "       \n",
        "        gen.train()  \n",
        "        losses = []\n",
        "        for i, labels, imgs in enumerate(get_batch(train, args.batch_size)): #labels: original images\n",
        "            img_1, img_2 = get_torch_vars(imgs, args.gpu)\n",
        "            out_1 = gen(simCLR(img_1, projection==False))\n",
        "            out_2 = gen(simCLR(img_2, projection==False))\n",
        "\n",
        "            loss = (criterion(out_1, labels) + criterion(out_2, labels))/2\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        print(epoch, loss.cpu().detach())\n",
        "\n",
        "    return gen"
      ],
      "metadata": {
        "id": "SuP0z2i1xdeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = AttrDict()\n",
        "args_dict = {\n",
        "    \"gpu\": True,\n",
        "    \"valid\": False,\n",
        "    \"checkpoint\": \"\",\n",
        "    \"colours\": \"./data/colours/colour_kmeans24_cat7.npy\",\n",
        "    \"model\": \"decoder\",\n",
        "    'learn_rate':0.001, \n",
        "    \"batch_size\": 64,\n",
        "    \"epochs\": 50,\n",
        "    \"seed\": 0,\n",
        "    \"plot\": False,\n",
        "    \"experiment_name\": \"Images inpainting\",\n",
        "    \"visualize\": False,\n",
        "    \"downsize_input\": False,\n",
        "}\n",
        "args.update(args_dict)\n",
        "simCLR = train_simCLR(data, args)"
      ],
      "metadata": {
        "id": "nl6szNhqBxYx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}