{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet Encoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3ILyrlCkk7-L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import PIL\n",
        "import tqdm\n",
        "import torch\n",
        "import random\n",
        "import shutil\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9nv55jiWYAx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_shape(debug, to_print):\n",
        "  if debug:\n",
        "    print(to_print)\n",
        "\n",
        "def double_conv_layers(in_channels, out_channels, kernel_size, activation=nn.ReLU, padding='same', batch_norm=True, coding_layer=False):\n",
        "  '''\n",
        "  Return Double Convolutional layers given the input parameters\n",
        "\n",
        "  in_channels: input channels for the first convolutional layer\n",
        "  out_channels: output channels for the second convolutional layer\n",
        "  kernel_size: kernel size to use for both the layers\n",
        "  activation: activaiton to apply to both the layers, should pass a activation function and not string.\n",
        "  padding: padding to be applied to the inputs, by default no padding.\n",
        "  batch_norm: if True applies nn.BatchNorm2d() after every Convolutional layer.\n",
        "  '''\n",
        "\n",
        "  if batch_norm:\n",
        "    double_conv = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n",
        "                                nn.BatchNorm2d(out_channels),\n",
        "                                activation(inplace=True),\n",
        "                                nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding),\n",
        "                                nn.BatchNorm2d(out_channels),\n",
        "                                activation(inplace=True) if not coding_layer else CONFIG['coding_layer_activation']())\n",
        "  else:\n",
        "    double_conv = nn.Sequential(\n",
        "                                nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding),\n",
        "                                activation(inplace=True),\n",
        "                                nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding),\n",
        "                                activation(inplace=True) if not coding_layer else CONFIG['coding_layer_activation']())\n",
        "  \n",
        "  return double_conv\n",
        "\n",
        "class ResidualUnit(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, activation, kernel=3, first=False, debug=False):\n",
        "    '''\n",
        "    Description: Initializes the residual unit depending upon whether the residual unit is the first or the second unit in \n",
        "                 2-residual unit \"layer\"(A \"layer\" in ResNet is usually bunch of residual units with same kernel size).\n",
        "\n",
        "    first : depending upon whether it is True or False the \"first\" or the \"second\" residual unit will be created\n",
        "    overall_first : if the residual unit is overall the first residual unit of the network or not.\n",
        "    '''\n",
        "    super().__init__()\n",
        "\n",
        "    self.first = first\n",
        "    self.debug = debug\n",
        "\n",
        "    if first:\n",
        "      self.conv1 = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel, 2, padding=1),\n",
        "                                 nn.BatchNorm2d(out_channels),\n",
        "                                 activation())\n",
        "      self.conv2 = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel, 1, padding='same'),\n",
        "                                 nn.BatchNorm2d(out_channels))\n",
        "      self.skipconv = nn.Sequential(nn.Conv2d(in_channels, out_channels, 1, 2, padding=0),\n",
        "                                    nn.BatchNorm2d(out_channels))\n",
        "      self.final_activation = activation()\n",
        "\n",
        "    else:\n",
        "      self.conv1 = nn.Sequential(nn.Conv2d(in_channels, in_channels, kernel, 1, padding='same'),\n",
        "                                 nn.BatchNorm2d(in_channels),\n",
        "                                 activation())\n",
        "      self.conv2 = nn.Sequential(nn.Conv2d(in_channels, in_channels, kernel, 1, padding='same'),\n",
        "                                 nn.BatchNorm2d(in_channels))\n",
        "      self.final_activation = activation()\n",
        "\n",
        "  def forward(self, input):\n",
        "    \n",
        "    print_shape(self.debug, '---------INSIDE RESIDUAL UNIT--------')\n",
        "\n",
        "    x = self.conv1(input)\n",
        "    print_shape(self.debug, f'After conv1 : {x.shape}')\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    print_shape(self.debug, f'After conv2 : {x.shape}')\n",
        "\n",
        "    if self.first:\n",
        "      # if it is the first residual unit of the residual block, to match the image \n",
        "      # size before adding skip connection we have to process the image\n",
        "      processed_input = self.skipconv(input)\n",
        "      print_shape(self.debug, f'Processing skip input to shape: {processed_input.shape}')\n",
        "      x = self.final_activation(x + processed_input) # skip connection\n",
        "    \n",
        "    else:\n",
        "      x = self.final_activation(x + input) # skip connection\n",
        "    \n",
        "    print_shape(self.debug, f'Output shape for Residual Unit : {x.shape}')\n",
        "\n",
        "    return x\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, activation, debug=False):\n",
        "    super().__init__()\n",
        "\n",
        "    self.debug = debug  \n",
        "\n",
        "    self.ru1 = ResidualUnit(in_channels, out_channels, activation=activation, first=True, debug=self.debug)\n",
        "    self.ru2 = ResidualUnit(out_channels, out_channels, activation=activation, debug=self.debug)\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = self.ru1(input)\n",
        "    x = self.ru2(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class ResNet18Encoder(nn.Module):\n",
        "  def __init__(self, first_layer_kernel=7, activation=nn.ReLU, debug=False):\n",
        "    super().__init__()\n",
        "\n",
        "    self.debug = debug\n",
        "\n",
        "    self.conv = nn.Conv2d(3, 64, first_layer_kernel, padding='same')\n",
        "\n",
        "    self.residual_block_64 = ResidualBlock(64, 64, activation=activation, debug=self.debug) # 4 conv layers\n",
        "    self.residual_block_128 = ResidualBlock(64, 128, activation=activation, debug=self.debug) # 4 conv layers\n",
        "    self.residual_block_256 = ResidualBlock(128, 256, activation=activation, debug=self.debug)# 4 conv layers\n",
        "    self.residual_block_512 = ResidualBlock(256, 512, activation=activation, debug=self.debug)# 4 conv layers\n",
        "    \n",
        "  def forward(self, input):\n",
        "    \n",
        "    print_shape(self.debug, f'Input shape : {input.shape}')\n",
        "    print_shape(self.debug, f'-------ENCODER--------')\n",
        "\n",
        "    x = self.conv(input)\n",
        "    print_shape(self.debug, f'After first conv : {x.shape}')\n",
        "\n",
        "    x1 = self.residual_block_64(x)\n",
        "    x2 = self.residual_block_128(x1)\n",
        "    x3 = self.residual_block_256(x2)\n",
        "    x = self.residual_block_512(x3)\n",
        "\n",
        "    return x, x3, x2, x1\n",
        "\n",
        "class UnetDecoder(nn.Module):\n",
        "  def __init__(self, activation=nn.ReLU, debug=False):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.debug = debug\n",
        "     \n",
        "    # combining upsample and conv2d layers as upsample_conv instead of using conv2dtranspose\n",
        "    # as upsample is more stable for GAN architecture and does not create checkerboard artificats.\n",
        "    self.upsample_conv_1 = nn.Sequential(nn.Upsample(scale_factor=2),\n",
        "                                         nn.Conv2d(512, 256, 3, 1, padding='same'),\n",
        "                                         activation())\n",
        "    \n",
        "    self.upsample_conv_2 = nn.Sequential(nn.Upsample(scale_factor=2),\n",
        "                                         nn.Conv2d(256, 128, 3, 1, padding='same'),\n",
        "                                         activation())\n",
        "    \n",
        "    self.upsample_conv_3 = nn.Sequential(nn.Upsample(scale_factor=2),\n",
        "                                         nn.Conv2d(128, 64, 3, 1, padding='same'),\n",
        "                                         activation())\n",
        "    \n",
        "    self.upsample_conv_4 = nn.Sequential(nn.Upsample(scale_factor=2),\n",
        "                                         nn.Conv2d(64, 64, 3, 1, padding='same'),\n",
        "                                         activation())\n",
        "    \n",
        "    self.up_conv_1 = double_conv_layers(512, 256, 3)\n",
        "    self.up_conv_2 = double_conv_layers(256, 128, 3)\n",
        "    self.up_conv_3 = double_conv_layers(128, 64, 3)\n",
        "\n",
        "    self.final_conv = nn.Conv2d(64, 3, 1, padding='same')\n",
        "\n",
        "  def forward(self, input, x3, x2, x1):\n",
        "    \n",
        "    print_shape(self.debug, f'-------DECODER-------')\n",
        "   \n",
        "    x = self.upsample_conv_1(input)\n",
        "    print_shape(self.debug, f'After upsample 1 : {x.shape}')\n",
        "\n",
        "    x = self.up_conv_1(torch.cat([x, x3], 1)) # skip connection\n",
        "    print_shape(self.debug, f'After up conv 1 : {x.shape}')\n",
        "\n",
        "    x = self.upsample_conv_2(x)\n",
        "    print_shape(self.debug, f'After upsample 2 : {x.shape}')\n",
        "\n",
        "    x = self.up_conv_2(torch.cat([x, x2], 1)) # skip connection\n",
        "    print_shape(self.debug, f'After up conv 2 : {x.shape}')\n",
        "\n",
        "    x = self.upsample_conv_3(x)\n",
        "    print_shape(self.debug, f'After upsample 3 : {x.shape}')\n",
        "\n",
        "    x = self.up_conv_3(torch.cat([x, x1], 1)) # skip connection\n",
        "    print_shape(self.debug, f'After up conv 3 : {x.shape}')\n",
        "\n",
        "    x = self.upsample_conv_4(x)\n",
        "    print_shape(self.debug, f'After upsample 4 : {x.shape}')\n",
        "\n",
        "    x = self.final_conv(x)\n",
        "    print_shape(self.debug, f'After final conv : {x.shape}')\n",
        "\n",
        "    return x\n",
        "\n",
        "class ResNetUNet(nn.Module):\n",
        "  def __init__(self, debug=False):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.debug =  debug\n",
        "    \n",
        "    self.encoder = ResNet18Encoder(debug=self.debug)\n",
        "    self.decoder = UnetDecoder(debug=self.debug)\n",
        "\n",
        "  def forward(self, input):\n",
        "\n",
        "    x, x3, x2, x1 = self.encoder(input)\n",
        "    x = self.decoder(x, x3, x2, x1)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "BEwsxmtIpLJr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.zeros(1, 3, 128, 128)\n",
        "resnet = ResNet18Encoder(debug=True)\n",
        "x = resnet(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps4xZ77lpB6h",
        "outputId": "60da909a-2648-4185-abae-e79320a36d7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape : torch.Size([1, 3, 128, 128])\n",
            "After first conv : torch.Size([1, 64, 128, 128])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 64, 64, 64])\n",
            "After conv2 : torch.Size([1, 64, 64, 64])\n",
            "Processing skip input to shape: torch.Size([1, 64, 64, 64])\n",
            "Output shape for Residual Unit : torch.Size([1, 64, 64, 64])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 64, 64, 64])\n",
            "After conv2 : torch.Size([1, 64, 64, 64])\n",
            "Output shape for Residual Unit : torch.Size([1, 64, 64, 64])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 128, 32, 32])\n",
            "After conv2 : torch.Size([1, 128, 32, 32])\n",
            "Processing skip input to shape: torch.Size([1, 128, 32, 32])\n",
            "Output shape for Residual Unit : torch.Size([1, 128, 32, 32])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 128, 32, 32])\n",
            "After conv2 : torch.Size([1, 128, 32, 32])\n",
            "Output shape for Residual Unit : torch.Size([1, 128, 32, 32])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 256, 16, 16])\n",
            "After conv2 : torch.Size([1, 256, 16, 16])\n",
            "Processing skip input to shape: torch.Size([1, 256, 16, 16])\n",
            "Output shape for Residual Unit : torch.Size([1, 256, 16, 16])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 256, 16, 16])\n",
            "After conv2 : torch.Size([1, 256, 16, 16])\n",
            "Output shape for Residual Unit : torch.Size([1, 256, 16, 16])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 512, 8, 8])\n",
            "After conv2 : torch.Size([1, 512, 8, 8])\n",
            "Processing skip input to shape: torch.Size([1, 512, 8, 8])\n",
            "Output shape for Residual Unit : torch.Size([1, 512, 8, 8])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 512, 8, 8])\n",
            "After conv2 : torch.Size([1, 512, 8, 8])\n",
            "Output shape for Residual Unit : torch.Size([1, 512, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.zeros(1, 512, 8, 8)\n",
        "x3 = torch.zeros(1, 256, 16, 16)\n",
        "x2 = torch.zeros(1, 128, 32, 32)\n",
        "x1 = torch.zeros(1, 64, 64, 64)\n",
        "decoder = UnetDecoder(debug=True)\n",
        "decoder(image, x3, x2, x1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmSfg6I0XCRF",
        "outputId": "97e358ba-a87f-4b08-8d5e-55ca5fb87b61"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------DECODER-------\n",
            "After upsample 1 : torch.Size([1, 256, 16, 16])\n",
            "After up conv 1 : torch.Size([1, 256, 16, 16])\n",
            "After upsample 2 : torch.Size([1, 128, 32, 32])\n",
            "After up conv 2 : torch.Size([1, 128, 32, 32])\n",
            "After upsample 3 : torch.Size([1, 64, 64, 64])\n",
            "After up conv 3 : torch.Size([1, 64, 64, 64])\n",
            "After upsample 4 : torch.Size([1, 64, 128, 128])\n",
            "After final conv : torch.Size([1, 3, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.zeros(1, 3, 128, 128)\n",
        "autoencoder = ResNetUNet(debug=True)\n",
        "x = autoencoder(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lgZkXAs2-J6",
        "outputId": "54bed1fb-091c-4124-b87c-77171355ed45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape : torch.Size([1, 3, 128, 128])\n",
            "-------ENCODER--------\n",
            "After first conv : torch.Size([1, 64, 128, 128])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 64, 64, 64])\n",
            "After conv2 : torch.Size([1, 64, 64, 64])\n",
            "Processing skip input to shape: torch.Size([1, 64, 64, 64])\n",
            "Output shape for Residual Unit : torch.Size([1, 64, 64, 64])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 64, 64, 64])\n",
            "After conv2 : torch.Size([1, 64, 64, 64])\n",
            "Output shape for Residual Unit : torch.Size([1, 64, 64, 64])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 128, 32, 32])\n",
            "After conv2 : torch.Size([1, 128, 32, 32])\n",
            "Processing skip input to shape: torch.Size([1, 128, 32, 32])\n",
            "Output shape for Residual Unit : torch.Size([1, 128, 32, 32])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 128, 32, 32])\n",
            "After conv2 : torch.Size([1, 128, 32, 32])\n",
            "Output shape for Residual Unit : torch.Size([1, 128, 32, 32])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 256, 16, 16])\n",
            "After conv2 : torch.Size([1, 256, 16, 16])\n",
            "Processing skip input to shape: torch.Size([1, 256, 16, 16])\n",
            "Output shape for Residual Unit : torch.Size([1, 256, 16, 16])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 256, 16, 16])\n",
            "After conv2 : torch.Size([1, 256, 16, 16])\n",
            "Output shape for Residual Unit : torch.Size([1, 256, 16, 16])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 512, 8, 8])\n",
            "After conv2 : torch.Size([1, 512, 8, 8])\n",
            "Processing skip input to shape: torch.Size([1, 512, 8, 8])\n",
            "Output shape for Residual Unit : torch.Size([1, 512, 8, 8])\n",
            "---------INSIDE RESIDUAL UNIT--------\n",
            "After conv1 : torch.Size([1, 512, 8, 8])\n",
            "After conv2 : torch.Size([1, 512, 8, 8])\n",
            "Output shape for Residual Unit : torch.Size([1, 512, 8, 8])\n",
            "-------DECODER-------\n",
            "After upsample 1 : torch.Size([1, 256, 16, 16])\n",
            "After up conv 1 : torch.Size([1, 256, 16, 16])\n",
            "After upsample 2 : torch.Size([1, 128, 32, 32])\n",
            "After up conv 2 : torch.Size([1, 128, 32, 32])\n",
            "After upsample 3 : torch.Size([1, 64, 64, 64])\n",
            "After up conv 3 : torch.Size([1, 64, 64, 64])\n",
            "After upsample 4 : torch.Size([1, 64, 128, 128])\n",
            "After final conv : torch.Size([1, 3, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GWKm-xRyevqp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}