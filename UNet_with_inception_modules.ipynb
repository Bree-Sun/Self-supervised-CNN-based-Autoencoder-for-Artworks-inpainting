{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNet with inception modules",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## To explore possible variations\n",
        "\n",
        "* Trying skip connections within double_conv_layers.\n",
        "* stacking inception modules."
      ],
      "metadata": {
        "id": "Mny60zstay6i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eDB41k6Plpht"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PIL\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def double_conv_layers(in_channels, out_channels, kernel_size, activation, padding='same', batch_norm=True):\n",
        "  '''\n",
        "  Return Double Convolutional layers given the input parameters\n",
        "\n",
        "  in_channels: input channels for the first convolutional layer\n",
        "  out_channels: output channels for the second convolutional layer\n",
        "  kernel_size: kernel size to use for both the layers\n",
        "  activation: activaiton to apply to both the layers, should pass a activation function and not string.\n",
        "  padding: padding to be applied to the inputs, by default no padding.\n",
        "  batch_norm: if True applies nn.BatchNorm2d() after every Convolutional layer.\n",
        "  '''\n",
        "\n",
        "  if batch_norm:\n",
        "    double_conv = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n",
        "                                nn.BatchNorm2d(out_channels),\n",
        "                                activation(inplace=True),\n",
        "                                nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding),\n",
        "                                nn.BatchNorm2d(out_channels),\n",
        "                                activation(inplace=True))\n",
        "  else:\n",
        "    double_conv = nn.Sequential(\n",
        "                                nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding),\n",
        "                                activation(inplace=True),\n",
        "                                nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding),\n",
        "                                activation(inplace=True))\n",
        "  \n",
        "  return double_conv\n",
        "\n",
        "\n",
        "class InceptionModule(nn.Module):\n",
        "  def __init__(self, input_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    \n",
        "    if input_channels % 4 == 0:\n",
        "      out_channels = [int(input_channels/4) for i in range(4)]\n",
        "    else:\n",
        "      out_channels = [int(input_channels//4) if i<3 else input_channels - (3*int(input_channels//4)) for i in range(4)]\n",
        "\n",
        "\n",
        "    self.channel_1 = nn.Conv2d(in_channels=input_channels, out_channels=out_channels[0], kernel_size=1, stride=1, padding='same')\n",
        "\n",
        "    self.channel_2 = nn.Sequential(nn.Conv2d(in_channels=input_channels, out_channels=out_channels[1], kernel_size=1, stride=1, padding='same'),\n",
        "                              nn.Conv2d(in_channels=out_channels[1], out_channels=out_channels[1], kernel_size=3, stride=1, padding='same'))\n",
        "    \n",
        "    self.channel_3 = nn.Sequential(nn.Conv2d(in_channels=input_channels, out_channels=out_channels[2], kernel_size=1, stride=1, padding='same'),\n",
        "                              nn.Conv2d(in_channels=out_channels[2], out_channels=out_channels[2], kernel_size=5, stride=1, padding='same'))\n",
        "    \n",
        "    self.channel_4 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "                              nn.Conv2d(in_channels=input_channels, out_channels=out_channels[3], kernel_size=1, stride=1, padding='same'))\n",
        "    \n",
        "  def forward(self, input):\n",
        "    print(f'input shape : {input.shape}')\n",
        "    x1 = self.channel_1(input)\n",
        "    print(f'Channel 1 : {x1.shape}')\n",
        "    x2 = self.channel_2(input)\n",
        "    print(f'Channel 2 : {x2.shape}')\n",
        "    x3 = self.channel_3(input)\n",
        "    print(f'Channel 3 : {x3.shape}')\n",
        "    x4 = self.channel_4(input)\n",
        "    print(f'Channel 4 : {x4.shape}')\n",
        "    x = torch.cat([x1, x2, x3, x4], 1)\n",
        "    print(f'Final shape : {x.shape}')\n",
        "    return x\n",
        "\n",
        "class UNet(nn.Module):\n",
        "  def __init__(self, \n",
        "               down_conv_out=[64, 128, 256, 512], \n",
        "               down_conv_ks=[3, 3, 3, 3],\n",
        "               down_conv_activation=nn.ReLU,\n",
        "               up_conv_out=[256, 128, 64],\n",
        "               up_conv_ks=[3, 3, 3],\n",
        "               up_conv_activation=nn.ReLU,\n",
        "               pad='same',\n",
        "               add_inception=False):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.down_conv_out = down_conv_out\n",
        "    self.down_conv_ks = down_conv_ks\n",
        "    self.down_conv_activation = down_conv_activation\n",
        "    self.up_conv_out = up_conv_out\n",
        "    self.up_conv_ks = up_conv_ks\n",
        "    self.up_conv_activation = up_conv_activation\n",
        "    self.pad = pad\n",
        "    self.add_inception = add_inception\n",
        "\n",
        "    # Down Conv Layers\n",
        "    self.down_conv1 = double_conv_layers(3, down_conv_out[0], down_conv_ks[0], down_conv_activation, padding=pad)\n",
        "    self.down_conv2 = double_conv_layers(down_conv_out[0], down_conv_out[1], down_conv_ks[1], down_conv_activation, padding=pad)\n",
        "    self.down_conv3 = double_conv_layers(down_conv_out[1], down_conv_out[2], down_conv_ks[2], down_conv_activation, padding=pad)\n",
        "    self.down_conv4 = double_conv_layers(down_conv_out[2], down_conv_out[3], down_conv_ks[3], down_conv_activation, padding=pad)\n",
        "\n",
        "    # Inception Modules\n",
        "    self.inception_module_1 = InceptionModule(down_conv_out[0])\n",
        "    self.inception_module_2 = InceptionModule(down_conv_out[1])\n",
        "    self.inception_module_3 = InceptionModule(down_conv_out[2])\n",
        "    \n",
        "    # Conv Transpose layers\n",
        "    self.up_transpose1 = nn.ConvTranspose2d(down_conv_out[3], up_conv_out[0], 2, 2)\n",
        "    self.up_transpose2 = nn.ConvTranspose2d(up_conv_out[0], up_conv_out[1], 2, 2)\n",
        "    self.up_transpose3 = nn.ConvTranspose2d(up_conv_out[1], up_conv_out[2], 2, 2)\n",
        "    \n",
        "    # Up Conv Layers\n",
        "    self.up_conv1 = double_conv_layers(down_conv_out[3], up_conv_out[0], up_conv_ks[0], up_conv_activation, padding=pad)\n",
        "    self.up_conv2 = double_conv_layers(up_conv_out[0], up_conv_out[1], up_conv_ks[1], up_conv_activation, padding=pad)\n",
        "    self.up_conv3 = double_conv_layers(up_conv_out[1], up_conv_out[2], up_conv_ks[2], up_conv_activation, padding=pad)\n",
        "\n",
        "    # final output conv\n",
        "    self.output_conv = nn.Conv2d(up_conv_out[2], 3, 1)\n",
        "\n",
        "    # Maxpooling\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "  def forward(self, input):\n",
        "\n",
        "    # Down Conv Encoder Part\n",
        "    print(f'Start : {input.shape}')\n",
        "    x1 = self.down_conv1(input)\n",
        "    if self.add_inception:\n",
        "      x1 = self.inception_module_1(x1)\n",
        "    print(f'After Down Conv 1 : {x1.shape}')\n",
        "    x = self.maxpool(x1)\n",
        "    print(f'After maxpool : {x.shape}')\n",
        "    x2 = self.down_conv2(x)\n",
        "    if self.add_inception:\n",
        "      x2 = self.inception_module_2(x2)\n",
        "    print(f'After Down Conv 2 : {x2.shape}')\n",
        "    x = self.maxpool(x2)\n",
        "    print(f'After maxpool : {x.shape}')\n",
        "    x3 = self.down_conv3(x)\n",
        "    if self.add_inception:\n",
        "      x3 = self.inception_module_3(x3)\n",
        "    print(f'After Down Conv 3 : {x3.shape}')\n",
        "    x = self.maxpool(x3)\n",
        "    print(f'After maxpool : {x.shape}')\n",
        "    x4 = self.down_conv4(x)\n",
        "    print(f'After Down Conv 4 : {x4.shape}')\n",
        "\n",
        "    # Up Conv Decoder Part\n",
        "    x = self.up_transpose1(x4)\n",
        "    print(f'After Up Transpose 1 : {x.shape}')\n",
        "    x = self.up_conv1(torch.cat([x, x3], 1)) # skip connection from down_conv3\n",
        "    print(f'After Up Conv 1 : {x.shape}')\n",
        "    x = self.up_transpose2(x)\n",
        "    print(f'After Up Transpose 2 : {x.shape}')\n",
        "    x = self.up_conv2(torch.cat([x, x2], 1)) # skip connection from down_conv2\n",
        "    print(f'After Up Conv 2 : {x.shape}')\n",
        "    x = self.up_transpose3(x)\n",
        "    print(f'After Up Transpose 3 : {x.shape}')\n",
        "    x = self.up_conv3(torch.cat([x, x1], 1)) # skip connection from down_conv1\n",
        "    print(f'After Up Conv 3 : {x.shape}')\n",
        "\n",
        "    # final output conv layer\n",
        "    x = self.output_conv(x)\n",
        "    print(f'After Final output conv : {x.shape}')\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "rWxYa9IkluBs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# without inception modules\n",
        "image = torch.zeros(1, 3, 128, 128)\n",
        "model = UNet(add_inception=False)\n",
        "x = model(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uavifefDx--2",
        "outputId": "dbf56356-2454-4338-f031-495a693e8f2c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start : torch.Size([1, 3, 128, 128])\n",
            "After Down Conv 1 : torch.Size([1, 64, 128, 128])\n",
            "After maxpool : torch.Size([1, 64, 64, 64])\n",
            "After Down Conv 2 : torch.Size([1, 128, 64, 64])\n",
            "After maxpool : torch.Size([1, 128, 32, 32])\n",
            "After Down Conv 3 : torch.Size([1, 256, 32, 32])\n",
            "After maxpool : torch.Size([1, 256, 16, 16])\n",
            "After Down Conv 4 : torch.Size([1, 512, 16, 16])\n",
            "After Up Transpose 1 : torch.Size([1, 256, 32, 32])\n",
            "After Up Conv 1 : torch.Size([1, 256, 32, 32])\n",
            "After Up Transpose 2 : torch.Size([1, 128, 64, 64])\n",
            "After Up Conv 2 : torch.Size([1, 128, 64, 64])\n",
            "After Up Transpose 3 : torch.Size([1, 64, 128, 128])\n",
            "After Up Conv 3 : torch.Size([1, 64, 128, 128])\n",
            "After Final output conv : torch.Size([1, 3, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with inception modules\n",
        "image = torch.zeros(1, 3, 128, 128)\n",
        "model = UNet(add_inception=True)\n",
        "x = model(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtL6Hix4yeb9",
        "outputId": "fce937ee-360e-4a96-823b-90ea9ae052a5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start : torch.Size([1, 3, 128, 128])\n",
            "input shape : torch.Size([1, 64, 128, 128])\n",
            "Channel 1 : torch.Size([1, 16, 128, 128])\n",
            "Channel 2 : torch.Size([1, 16, 128, 128])\n",
            "Channel 3 : torch.Size([1, 16, 128, 128])\n",
            "Channel 4 : torch.Size([1, 16, 128, 128])\n",
            "Final shape : torch.Size([1, 64, 128, 128])\n",
            "After Down Conv 1 : torch.Size([1, 64, 128, 128])\n",
            "After maxpool : torch.Size([1, 64, 64, 64])\n",
            "input shape : torch.Size([1, 128, 64, 64])\n",
            "Channel 1 : torch.Size([1, 32, 64, 64])\n",
            "Channel 2 : torch.Size([1, 32, 64, 64])\n",
            "Channel 3 : torch.Size([1, 32, 64, 64])\n",
            "Channel 4 : torch.Size([1, 32, 64, 64])\n",
            "Final shape : torch.Size([1, 128, 64, 64])\n",
            "After Down Conv 2 : torch.Size([1, 128, 64, 64])\n",
            "After maxpool : torch.Size([1, 128, 32, 32])\n",
            "input shape : torch.Size([1, 256, 32, 32])\n",
            "Channel 1 : torch.Size([1, 64, 32, 32])\n",
            "Channel 2 : torch.Size([1, 64, 32, 32])\n",
            "Channel 3 : torch.Size([1, 64, 32, 32])\n",
            "Channel 4 : torch.Size([1, 64, 32, 32])\n",
            "Final shape : torch.Size([1, 256, 32, 32])\n",
            "After Down Conv 3 : torch.Size([1, 256, 32, 32])\n",
            "After maxpool : torch.Size([1, 256, 16, 16])\n",
            "After Down Conv 4 : torch.Size([1, 512, 16, 16])\n",
            "After Up Transpose 1 : torch.Size([1, 256, 32, 32])\n",
            "After Up Conv 1 : torch.Size([1, 256, 32, 32])\n",
            "After Up Transpose 2 : torch.Size([1, 128, 64, 64])\n",
            "After Up Conv 2 : torch.Size([1, 128, 64, 64])\n",
            "After Up Transpose 3 : torch.Size([1, 64, 128, 128])\n",
            "After Up Conv 3 : torch.Size([1, 64, 128, 128])\n",
            "After Final output conv : torch.Size([1, 3, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet(down_conv_out=[32, 64, 128, 256],\n",
        "             down_conv_ks=[5, 3, 3, 3],\n",
        "             down_conv_activation=nn.SELU,\n",
        "             up_conv_out=[128, 64, 32],\n",
        "             up_conv_activation=nn.SELU)\n",
        "x = model(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rGZgHrIRJ4G",
        "outputId": "854c7fc6-c6d7-4a22-dd96-9a3e53df8965"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start : torch.Size([1, 3, 128, 128])\n",
            "After Down Conv 1 : torch.Size([1, 32, 128, 128])\n",
            "After maxpool : torch.Size([1, 32, 64, 64])\n",
            "After Down Conv 2 : torch.Size([1, 64, 64, 64])\n",
            "After maxpool : torch.Size([1, 64, 32, 32])\n",
            "After Down Conv 3 : torch.Size([1, 128, 32, 32])\n",
            "After maxpool : torch.Size([1, 128, 16, 16])\n",
            "After Down Conv 4 : torch.Size([1, 256, 16, 16])\n",
            "After Up Transpose 1 : torch.Size([1, 128, 32, 32])\n",
            "After Up Conv 1 : torch.Size([1, 128, 32, 32])\n",
            "After Up Transpose 2 : torch.Size([1, 64, 64, 64])\n",
            "After Up Conv 2 : torch.Size([1, 64, 64, 64])\n",
            "After Up Transpose 3 : torch.Size([1, 32, 128, 128])\n",
            "After Up Conv 3 : torch.Size([1, 32, 128, 128])\n",
            "After Final output conv : torch.Size([1, 3, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ANDwmIjBRNeA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}